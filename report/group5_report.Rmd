---
title: 'Deep Learning Project'
author: "Ilia Azizi, Alexandre Schroeter"
date: "`r format(Sys.time(), '%d %B, %Y')`"   
output:
  html_document:
    theme: cerulean
    highlight: textmate
    toc: true
    toc_float: true
    depth: 1
bibliography: ref.bibtex
biblio-style: "apalike"
link-citations: true
---
<style type="text/css">

body{ /* Normal  */
      font-size: 18px;
  }
  
h1.title {
  font-size: 40px;
  text-align: center
}

.pad {
    padding-top: 200px; 
}

</style>


<style>
table th:first-of-type {
    width: 40%;
}
table th:nth-of-type(2) {
    width: 20%;
}
table th:nth-of-type(3) {
    width: 5%;
}
table th:nth-of-type(4) {
    width: 15%;
}
table th:nth-of-type(5) {
    width: 20%;
}

</style>

```{r, include = F}
library(keras)
library(cloudml)
library(tfruns)
library(kerasR)
library(caret)
library(here)
library(scales)
```
## <strong>Introduction</strong>
The COVID-19 pandemic, with the SARS-CoV-2 virus unknown only 6 months ago, has impacted our lives tremendously. To date, no vaccine or effective treatment has been found. While the "Great Lockdown" is being slowly lifted in Europe and the US, 2 sets of measures seem critical. The first one is basic hygiene gestures to prevent infection from spreading. The second is the capability of detecting and tracing every person who may have been infected and placing her in quarantine. 

At the moment, different types of testing take place -@kent_2020. The first one, accounting for a vast majority of tests, is called **polymerise chain reaction (PCR) testing**. It is searching for viral RNA and is only possible when the patient is actively infected. The test is performed using nasopharyngeal swab. This is a very labour intensive procedure, where errors are likely to occur. False negatives can be as high as 30%. 

The second category of tests is called **serologic testing**. It does not specifically search for the virus RNA but for antibodies to COVID-19. The test is carried by using a blood sample. Antibodies are produced by the body when an infection with a specific virus takes place. The antibodies are generally produced one or two weeks after infection and are useful to asses who has been in contact with the virus. This kind of test is less useful to detect an infection early and is mainly interesting for epidemiologists to give a clearer picture of the sanitary situation. The result of this test only display who has been infected but it is not possible to determine if and for how long immunity has been acquired for this virus. 

Other tests are under development, notably a **lateral flow assays** which look for a biological marker in different samples (urine, blood, saliva,...). It works just like a pregnancy test and can be used for in-home testing. Other pharmaceuticals are developing **rapid in-clinic antigen testing**. In this procedure, the analyser device uses cartridges where biological components in each cartridge is used to prove if the patient has SARS-CoV-2 or any of 9 other respiratory dieases. 

Depending on the test type and where it is performed, the price can be high. Furthermore, reagents -@heil_2020 are also a key components of most tests and are in short supply. China and the US are producers and exporters of reagents but both countries have been hit by the pandemic. 

All in all, tests are in great demand. 

Up to now, only a fraction of the population has been tested, and even if testing every person may be useless, having enough capabilities is central. 


```{r pressure, echo=FALSE, out.width = '100%', message = F, fig.cap = "Number of tests per thousand -@data_2020"}
library(here)
knitr::include_graphics(here("images/tests.png"))
```

Even small countries like Iceland or Luxembourg have only been able to carry 100 tests per thousand inhabitants. 

SARS-CoV-2 transmission is difficult to trace because symptoms can appear as long as 14 days after exposure to the virus. Most symptomatic people have fever, tiredness and a dry cough among others. People are very susceptible to developing a pneumonia. 

Another method used to confirm a diagnosis is the use of chest x-rays to detect the virus. 

However, this method also has advantages and drawbacks. First, it can be carried in almost every country becausethe material to conduct the test is ubiquitous. Second, it is less costly than a CT scan or PCR test and most of the time CT scans can only be carried in bigger hospitals. Finally, X-rays can be conducted more safely than the nasal swab method because they do not risk aerosolizing the virus when the test is conducted. 

X-rays drawbacks include increased difficulty of detecting asymptomatic cases, no at-home testing and finally the use of a radiologist needed to analyze the pictures.

Still, no method will solve the problem on its own and as explained above, a variety of methods may help overcome the shortage. For example, it could be interesting to use X-rays primarily to determine if one is COVID positive so that PCR tests may be allocated elsewhere, where X-rays cannot be used. 

Therefore, having a cheap, fast and reliable method of X-rays analysis is our motivation. -@hemdan2020covidxnet

## <strong>Research question</strong>
Thus, our research question is 

> **Can Deep Learning be used to rapidly and accurately analyze X-rays pictures to predict COVID-19 ?**

## <strong>Previous approaches </strong>
| Study               | Type of images | Number of cases                                       | Method used            | Accuracy (%) |
|---------------------|----------------|-------------------------------------------------------|------------------------|--------------|
| **Ioannis et al.** -@Apostolopoulos_2020  | Chest X-ray    | 224 COVID-19(+)<br> 700 Pneumonia<br> 504 healthy     | VGG-19                 | 93.48        |
| **Wang and Wong** -@wang2020covidnet   | Chest X-ray    | 53 COVID-19(+)<br> 5526 COVID-19(-)<br> 8066 Healthy  | COVID-NET              | 92.4         |
| **Sethy and Behra** -@articlesethy | Chest X-ray    | 25 COVID-19(+)<br> 25 COVID-19(-)                     | ResNet50+<br> SVM      | 95.38        |
| **Hemdan et al.** -@hemdan2020covidxnet  | Chest X-ray    | 25 COVID-19(+)<br> 25 Normal                          | COVIDX-Net             | 90.0         |
| **Narin et al.** -@narin2020automatic   | Chest X-ray    | 50 COVID-19(+)<br> 50 COVID-19(-)                     | Deep CNN<br> ResNet-50 | 98.0         |
| **Ozturk et al.**  -@ozturk2020automated | Chest X-ray    | 125 COVID-19(+)<br> 500 No-Findings                   | DarkCovidNet           | 98.08        |
| **Ozturk et al.**-@ozturk2020automated  | Chest X-ray    | 125 COVID-19(+)<br> 500 Pneumonia<br> 500 No-Findings | DarkCovidNet           | 87.02        |

The traditional approach consists of using Convolutional Neural Networks(CNN) to solve this task. 
Half of the previous approaches use transfer learning for the purpose. VGG_19 and ResNet50 are the pretrained networks of preference. Sethy and Behra use a Support Vector Machine on top of their CNN, at the very end of the dense layers in place of the traditional softmax activation function. 

The other half of the approaches use customized networks such as the COVIDX-Net or the DarkCovidNet whose architecture is based on the DarkNet model. The DarkNet model is a model available on MATLAB which is 19 layers deep.


## <strong>Data</strong>
As SARS-CoV-2 is a new virus, most X-rays available come from different sources. At the time being, 5 of them are worth mentionning:

a.<a href="https://cases.rsna.org/coronavirus/"> The Radiological Society of North America (RSNA)</a> <br>
b. <a href=" https://radiopaedia.org/search?utf8=%E2%9C%93&q=covid&scope=all&lang=us/"> Radiopaedia</a><br>
c. <a href="https://www.sirm.org/en/category/articles/covid-19-database/">The Italian Society of Medical and Interventional Radiology (SIRM)</a><br>
d. <a href="https://www.eurorad.org/"> Eurorad.</a><br>
e. <a href="https://coronacases.org/forum/coronacases-org-helping-radiologists-to-help-people-in-more-than-100-countries-1"> Coronacases.org</a>

As most of the data is not centralized, and therefore not always reliable, one of the leading repos on COVID-19 positive (pneumonia) X-rays is https://github.com/ieee8023/covid-chestxray-dataset. Data can be downloaded freely. 
This repo is approved by the University of Montreal's Ethics Committee and is being continuously updated. Furthermore, previous studies have already used this repo. We sample 140 pictures of it. 

To find COVID-19 negative pictures, we use another dataset provided by https://data.mendeley.com/datasets/rscbjbr9sj/3. It is named the *Kermany Dataset*. 

As the number of images of COVID+ at our disposal if fairly limited, we build a train set, a small test set and a large test set. This will be specified below. 

**The total size of the data 1.28GB with 5893 items. **


## <strong>Methodology</strong>

## CNN models{.tabset .tabset-fade}
2 questions which naturally arise as we conduct our experiments are: 

* Can we accurately identify COVID+ individuals from COVID- individuals (binary classification task) ? 
* Can we accurately identify COVID+ individuals from COVID- individuals from individuals who have a viral pneumonia other than COVID from individuals who have a bacterial pneumonia (multiclass classification task with 4 outcome classes) ?

From the literature, we decide to use 2 different models, other than the ones which have been used so far. We decide to use transfer learning for our tasks. We train and test 2 CNN pretrained networks per task and use them as a basis for our model. We then add dense layers on top of them. 

* **VGG16**: this pretrained model built on the ImageNet dataset has a size of 528MB a Top-1 accuracy of 0.713. It is 23-layer deep and has 138 Mio parameters making it a very large model.


* **DenseNet201**: this pretrained model built on the ImageNet dataset has a size of 80MB a Top-1 accuracy of 0.773. It is 201-layer deep and has 20 Mio parameters. 

Both models are thus very different in size and in depth. 

&nbsp;
&nbsp;
&nbsp;

We select our best models based on the categorical accuracy as a first metric and the validation loss if there is a tie in categorical accuracy. 

**Binary classification**
&nbsp;

We use the 140 COVID+ images as well as 140 COVID- images, so 280 images in total. We use 80% (224 images) of these as a training set and 20% (56 images) as a testing set. 50% of the training set will build the validation set. We tune our models on Google Cloud. 
&nbsp;
To challenge our model, we also build a larger test set made of 29 COVID+ and 1573 COVID- images

<center>
<html>
<body >
<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-i7a5{font-family:Verdana, Geneva, sans-serif !important;;font-size:14px;text-align:left;vertical-align:top}
.tg .tg-5x9q{font-family:Verdana, Geneva, sans-serif !important;;font-size:14px;font-weight:bold;text-align:left;vertical-align:top}
.tg .tg-3zvv{font-family:Verdana, Geneva, sans-serif !important;;font-size:14px;text-align:center;vertical-align:top}
</style>
<table class="tg" width = 50%>
<thead>
  <tr>
    <th class="tg-i7a5"; width = 20%></th>
    <th class="tg-5x9q"; width = 15%>COVID+</th>
    <th class="tg-5x9q"; width = 15%>COVID-</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-i7a5">Train set</td>
    <td class="tg-3zvv">140</td>
    <td class="tg-3zvv">140</td>
  </tr>
  <tr>
    <td class="tg-i7a5">Small test set</td>
    <td class="tg-3zvv">28</td>
    <td class="tg-3zvv">28</td>
  </tr>
  <tr>
    <td class="tg-i7a5">Large test set</td>
    <td class="tg-3zvv">28</td>
    <td class="tg-3zvv">1572</td>
  </tr>
</tbody>
</table>

</body>
</html>
</center>

&nbsp;
&nbsp;
&nbsp;

**Multiclass classification**

Again, we build one training set and two testing sets; a small one and a large one. The table below indicates how many images were used per class and per set. 

<center>
<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-i7a5{font-family:Verdana, Geneva, sans-serif !important;;font-size:14px;text-align:left;vertical-align:top}
.tg .tg-5x9q{font-family:Verdana, Geneva, sans-serif !important;;font-size:14px;font-weight:bold;text-align:left;vertical-align:top}
.tg .tg-3zvv{font-family:Verdana, Geneva, sans-serif !important;;font-size:14px;text-align:center;vertical-align:top}
</style>
<table class="tg" width = 80%>
<thead>
  <tr>
    <th class="tg-i7a5"; width = 20%></th>
    <th class="tg-5x9q"; width = 10%>COVID+</th>
    <th class="tg-5x9q"; width = 10%>COVID-</th>
    <th class="tg-5x9q"; width = 10%>Viral Pneumonia</th>
    <th class="tg-5x9q"; width = 10%>Bacterial Pneumonia</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-i7a5">Train set</td>
    <td class="tg-3zvv">112</td>
    <td class="tg-3zvv">112</td>
    <td class="tg-3zvv">112</td>
    <td class="tg-3zvv">112</td>
  </tr>
  <tr>
    <td class="tg-i7a5">Small test set</td>
    <td class="tg-3zvv">28</td>
    <td class="tg-3zvv">28</td>
    <td class="tg-3zvv">28</td>
    <td class="tg-3zvv">28</td>
  </tr>
  <tr>
    <td class="tg-i7a5">Large test set</td>
    <td class="tg-3zvv">28</td>
    <td class="tg-3zvv">1583</td>
    <td class="tg-3zvv">1494</td>
    <td class="tg-3zvv">2788</td>
  </tr>
</tbody>
</table>
</center>

&nbsp;
&nbsp;



### Binary VGG16
Structure of the model :

* VGG16 base
* 2 hidden layers with 100 and 50 nodes respectively
* Final layer with 2 nodes and the softmax activation function
* SeLU activation function in each hidden layer
* Dropout rate of 0.2
* $l_1$ regularization penalty of 0.001
* Adamax optimizer with a learning rate of 0.001


We train this model for 30 epochs and we use early stopping with patience = 7. 
&nbsp;
```{r, include = F, results = "hide"}
#load model

generator_test <-
  image_data_generator(
    rescale = 1 / 255
  )
test_binary <- flow_images_from_directory(
  #directory = gs_data_dir_local("gs://covid-pw2/final_data/binary/test"),
  directory = here::here("data/final_data/binary/test"),
  target_size = c(224, 224),
  generator = generator_test,
  batch_size = 8
)

large_test_binary <- flow_images_from_directory(
  #directory = gs_data_dir_local("gs://covid-pw2/final_data/binary/test"),
  directory = here::here("data/binary_large_test"),
  target_size = c(224, 224),
  generator = generator_test,
  batch_size = 8
)


test_mc <- flow_images_from_directory(
  #directory = gs_data_dir_local("gs://covid-pw2/final_data/binary/test"),
  directory = here::here("data/final_data/multiclass/test"),
  target_size = c(224, 224),
  generator = generator_test,
  batch_size = 8
)

large_test_mc <- flow_images_from_directory(
  #directory = gs_data_dir_local("gs://covid-pw2/final_data/binary/test"),
  directory = here::here("data/multiclass_large_test"),
  target_size = c(224, 224),
  generator = generator_test,
  batch_size = 8
)


```
&nbsp;
```{r, echo = F, fig.align="center"}
vgg16_binary <- load_model_hdf5(here::here("best_models/vgg16_binary/best_second_vgg16_binary.h5"))
```


```{r, echo = F, fig.align="center"}
#load model
summary(vgg16_binary)
```
&nbsp;
&nbsp;

**Small test set**
```{r, echo = F, fig.align="center"}
#load model

b16s <- vgg16_binary %>% evaluate_generator(generator = test_binary, steps = test_binary$n / test_binary$batch_size)

print(b16s)


# predicted <- vgg16_binary %>% predict_generator(generator = test, steps = test$batch_size / test$n)
# predicted_tr <- (apply(predicted, MARGIN = 1, which.max)-1) %>% as.factor()
# 
# observed <- test$classes %>% as.factor()
# caret::confusionMatrix(predicted_tr, observed)
# 
# table(predicted_tr, observed)
```
Based on our small test set, we can predict COVID patients in  `r label_percent(accuracy = 4)(round(b16s$categorical_accuracy,4))` of the cases.
&nbsp;
&nbsp;
&nbsp;
&nbsp;

**Large test set**
```{r, echo = F, fig.align="center"}
#load model
b16l <- vgg16_binary %>% evaluate_generator(generator = large_test_binary, steps = large_test_binary$n / large_test_binary$batch_size)

print(b16l)


```
When we test our model on the large dataset, the accuracy reaches `r label_percent(accuracy = 4)(round(b16l$categorical_accuracy,4))`.  

&nbsp;

### Binary DenseNet201
Structure of the model :

* DenseNet201 base
* 2 hidden layers with 100 and 100 nodes respectively
* Final layer with 2 nodes and the softmax activation function
* ReLU activation function in each hidden layer
* Dropout rate of 0.2
* No $l_1$ regularization penalty
* Adamax optimizer with a learning rate of 0.001

We train this model for 30 epochs and we use early stopping with patience = 7. 

```{r, include = F, results = "hide"}
den201_binary <- load_model_hdf5(here::here("best_models/densenet201_binary/best_densenet201_binary050.h5"))
```


```{r, echo = F, fig.align="center"}
#load model
summary(den201_binary)
```
&nbsp;
&nbsp;

**Small test set**
```{r, echo = F, fig.align="center"}
bindens <- den201_binary %>% evaluate_generator(generator = test_binary, steps = test_binary$n / test_binary$batch_size)
print(bindens)
```
Based on our small test set, we can predict COVID patients in `r label_percent(accuracy = 4)(round(bindens$categorical_accuracy,4))` of the cases. 
&nbsp;
&nbsp;
&nbsp;
&nbsp;


**Large test set**
```{r, echo = F, fig.align="center"}
bindenl <- den201_binary %>% evaluate_generator(generator = large_test_binary, steps = large_test_binary$n / large_test_binary$batch_size)

print(bindenl)
```
When we test our model on the large dataset, the accuracy reaches `r label_percent(accuracy = 4)(round(bindenl$categorical_accuracy,4))`.
&nbsp;

### Multiclass VGG16
Structure of the model :

* VGG16 base
* 2 hidden layers with 100 and 50 nodes respectively
* Final layer with 4 nodes and the softmax activation function
* ReLU activation function in each hidden layer
* No dropout rate
* No $l_1$ regularization penalty
* RMSprop optimizer with a learning rate of 0.0001



We train this model for 30 epochs and we use early stopping with patience = 7. 

```{r, include = F, results = "hide"}
vgg16_mc <- load_model_hdf5(here::here("best_models/vgg16_mc/best_vgg16_mc.h5"))
```


```{r, echo = F, fig.align="center"}
#load model
summary(vgg16_mc)
```
&nbsp;
&nbsp;

**Small test set**

```{r, echo = F, fig.align="center"}
mc16s <- vgg16_mc %>% evaluate_generator(generator = test_mc, steps = test_mc$n / test_mc$batch_size)

print(mc16s)

```
Based on our small test set, we can predict COVID patients in `r label_percent(accuracy = 4)(round(mc16s$categorical_accuracy,4))` of the cases.
&nbsp;
&nbsp;
&nbsp;
&nbsp;

**Large test set**
```{r, echo = F, fig.align="center"}
mc16l <- vgg16_mc %>% evaluate_generator(generator = large_test_mc, steps = large_test_mc$n / large_test_mc$batch_size)

print(mc16l)

```
When we test our model on the large dataset, the accuracy reaches `r label_percent(accuracy = 4)(round(mc16l$categorical_accuracy,4))`.


### Multiclass DenseNet201
We discard this model because the accuracy of the best model after tuning is less than 60%. 

## {-}

## Limitations / Improvements
Based on our two analyses, we think that further improvements could be made. First, X-rays of healthy patients are in fact images of children because we did not find reliable data of adults. This is one of the main limitations of our project. Did the model learn to correctly identify features specific to COVID infection or did it learn to distinguish between adults and children ? The most likely answer is that our model is sensitive to specific features of COVID+ patients. Still, it would be good to have access to healthy adults data to check if this is truly the case. 

Another improvement which could be made is access to more COVID+ images. At the time being, too few images are freely accessible. This issue is not specific to our project because researchers used at most 224 images of infected patients. 

If we had been able to compute the confusion matrix, then we could have further elaborated on sensitivity and specificity. This is even more important in an epidemiological context. Even if we used the validation categorical accuracy and the validation loss as our first and second metrics, the most important criterion besides these is sensitivity. False negatives are much more costly because this would mean undetecting infected people. 

So the next steps would be to collect images of healthy adults, to have more COVID chest X-rays and to use the sensitivity as a metric to improve how efficient our model can be. 


## <strong>References</strong>


